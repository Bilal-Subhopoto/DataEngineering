{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cleaningsites_pkl.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNC7SK4nJS0HOxDAZ/TbBfC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bilal-Subhopoto/DataEngineering/blob/main/Bilal/Practice/cleaningsites_pkl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97Jv_Rl4wrNz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "343ac61e-25c9-4503-cc27-47c6a9c8d2cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tldextract in /usr/local/lib/python3.7/dist-packages (3.1.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from tldextract) (2.10)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tldextract) (2.23.0)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.7/dist-packages (from tldextract) (1.5.1)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract) (3.4.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract) (2021.10.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from requests-file>=1.4->tldextract) (1.15.0)\n",
            "Requirement already satisfied: redis in /usr/local/lib/python3.7/dist-packages (4.1.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.7/dist-packages (from redis) (21.3)\n",
            "Requirement already satisfied: importlib-metadata>=1.0 in /usr/local/lib/python3.7/dist-packages (from redis) (4.8.2)\n",
            "Requirement already satisfied: deprecated>=1.2.3 in /usr/local/lib/python3.7/dist-packages (from redis) (1.2.13)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis) (1.13.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=21.3->redis) (3.0.6)\n"
          ]
        }
      ],
      "source": [
        "# importing libraries\n",
        "!pip install tldextract\n",
        "import tldextract\n",
        "import pickle\n",
        "!pip install redis\n",
        "import redis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read the contents of a txt file and make a list\n",
        "with open('/content/All_urls.txt', 'r') as B:\n",
        "    links_list = [line.strip() for line in B]\n",
        "print(len(links_list))#6163\n",
        "links_list"
      ],
      "metadata": {
        "id": "X6V4bzamw8Wo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add clean sites file and convert to list\n",
        "with open('/content/append these after cleaning all the scraped links.txt', 'r') as B:\n",
        "    links_list2 = [line.strip() for line in B]\n",
        "print(len(links_list2))#768\n",
        "links_list2"
      ],
      "metadata": {
        "id": "x4AAcPep9Xds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean and append to cleanUrl_list\n",
        "cleanUrl_list = []\n",
        "\n",
        "for urls in links_list:\n",
        "  cleanUrl = tldextract.extract(urls)\n",
        "  if len(cleanUrl.subdomain) == 0:\n",
        "    linkss = cleanUrl.domain+'.'+cleanUrl.suffix\n",
        "  elif  cleanUrl.subdomain[0:3] == 'www':\n",
        "    cu = cleanUrl.subdomain+'.'+cleanUrl.domain+'.'+cleanUrl.suffix\n",
        "    linkss = cu[4:]\n",
        "  else:\n",
        "    linkss = cleanUrl.subdomain+'.'+cleanUrl.domain+'.'+cleanUrl.suffix\n",
        "  cleanUrl_list.append(linkss)#append every clean url to a list\n",
        "cleanUrl_list"
      ],
      "metadata": {
        "id": "kcqHwE9hxwwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "master_list = cleanUrl_list+links_list2\n",
        "print(len(master_list))\n",
        "Uni_master_set = set(master_list)\n",
        "print(len(Uni_master_set))\n",
        "Uni_master_list = list(Uni_master_set)\n",
        "print(len(Uni_master_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KzhbsCwY6Rz",
        "outputId": "27f6ea3d-2154-4ea4-9258-fd0ef0831a70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6931\n",
            "4452\n",
            "4452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# write cleanUrl_list to pkl file\n",
        "open_file = open('/content/All_Clean_urls.pkl', \"wb\")\n",
        "pickle.dump(Uni_master_list, open_file)\n",
        "open_file.close()"
      ],
      "metadata": {
        "id": "xZo84GyYzA_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# writes list to a txt file\n",
        "with open('/content/All_Clean_urls.txt','w+') as f:\n",
        "\tfor link in Uni_master_list:\n",
        "\t\tf.write('%s\\n'%link)"
      ],
      "metadata": {
        "id": "CYQVinRuae_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read/print pkl file\n",
        "open_file = open('/content/All_Clean_urls.pkl', \"rb\")\n",
        "loaded_list = pickle.load(open_file)\n",
        "open_file.close()\n",
        "print(len(loaded_list))\n",
        "print(loaded_list)"
      ],
      "metadata": {
        "id": "c0kiCpJ1zX2w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}